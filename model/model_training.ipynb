{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#libraries for model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score  #useful for evaluating performance of probabilistic classifiers\n",
    "from imblearn.over_sampling import SMOTE \n",
    "#classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Crime_Type</th>\n",
       "      <th>Charges_Filed</th>\n",
       "      <th>Time_Served_Months</th>\n",
       "      <th>Prior_Criminal_History</th>\n",
       "      <th>Risk_of_Flight</th>\n",
       "      <th>Influence_on_Trial</th>\n",
       "      <th>Bail_Decision</th>\n",
       "      <th>Socio_Economic_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyber Crime</td>\n",
       "      <td>['IPC 379', 'IPC 307', 'IPC 302']</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945674</td>\n",
       "      <td>0.115675</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Drug-related</td>\n",
       "      <td>['Narcotics Act', 'Narcotics Act']</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408927</td>\n",
       "      <td>0.946264</td>\n",
       "      <td>Granted</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Economic</td>\n",
       "      <td>['Cyber Laws']</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661970</td>\n",
       "      <td>0.733362</td>\n",
       "      <td>Granted</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Drug-related</td>\n",
       "      <td>['IPC 307']</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464855</td>\n",
       "      <td>0.637499</td>\n",
       "      <td>Granted</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Drug-related</td>\n",
       "      <td>['Economic Offenses Act', 'Narcotics Act', 'IP...</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630589</td>\n",
       "      <td>0.645278</td>\n",
       "      <td>Granted</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Crime_Type  \\\n",
       "0           0   Cyber Crime   \n",
       "1           1  Drug-related   \n",
       "2           2      Economic   \n",
       "3           3  Drug-related   \n",
       "4           4  Drug-related   \n",
       "\n",
       "                                       Charges_Filed  Time_Served_Months  \\\n",
       "0                  ['IPC 379', 'IPC 307', 'IPC 302']                  33   \n",
       "1                 ['Narcotics Act', 'Narcotics Act']                   7   \n",
       "2                                     ['Cyber Laws']                  41   \n",
       "3                                        ['IPC 307']                   8   \n",
       "4  ['Economic Offenses Act', 'Narcotics Act', 'IP...                  37   \n",
       "\n",
       "   Prior_Criminal_History  Risk_of_Flight  Influence_on_Trial Bail_Decision  \\\n",
       "0                       0        0.945674            0.115675      Rejected   \n",
       "1                       0        0.408927            0.946264       Granted   \n",
       "2                       0        0.661970            0.733362       Granted   \n",
       "3                       0        0.464855            0.637499       Granted   \n",
       "4                       1        0.630589            0.645278       Granted   \n",
       "\n",
       "  Socio_Economic_Status  \n",
       "0                   Low  \n",
       "1                   Low  \n",
       "2                  High  \n",
       "3                  High  \n",
       "4                   Low  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('modified_bail_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Bail_Decision','Time_Served_Months','Risk_of_Flight','Prior_Criminal_History'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Bail_Decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(sparse_output =False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 357), (400, 357))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_train =  X_train.toarray()\n",
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an Evalutation Functionn to give all metrics after model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted, predicted_proba):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    precision = precision_score(true, predicted, pos_label=1)\n",
    "    recall = recall_score(true, predicted, pos_label=1)\n",
    "    f1 = f1_score(true, predicted, pos_label=1)\n",
    "    roc_auc = roc_auc_score(true, predicted_proba) if predicted_proba  is not None else None\n",
    "    return accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Random Forest Classifier\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20],\n",
    "        'min_samples_split': [2, 10]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1.0],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    },\n",
    "    \"Gradient Boosting Classifier\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Cross-validated Fq Score (Training): 0.5403\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.6574\n",
      "-Precision: 0.6441\n",
      "-Recall: 0.7034\n",
      "-f1 Score: 0.6725\n",
      "-ROC AUC: 0.7341\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4625\n",
      "-Precision: 0.4696\n",
      "-Recall: 0.5373\n",
      "-f1 Score: 0.5012\n",
      "-ROC AUC 0.4704\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Random Forest Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5239\n",
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.8814\n",
      "-Precision: 0.8563\n",
      "-Recall: 0.9165\n",
      "-f1 Score: 0.8854\n",
      "-ROC AUC: 0.9612\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4550\n",
      "-Precision: 0.4601\n",
      "-Recall: 0.4876\n",
      "-f1 Score: 0.4734\n",
      "-ROC AUC 0.4605\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Decision Tree Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5230\n",
      "Decision Tree Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 1.0000\n",
      "-Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "-f1 Score: 1.0000\n",
      "-ROC AUC: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.5200\n",
      "-Precision: 0.5254\n",
      "-Recall: 0.4627\n",
      "-f1 Score: 0.4921\n",
      "-ROC AUC 0.5203\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Support Vector Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5020\n",
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.7294\n",
      "-Precision: 0.7396\n",
      "-Recall: 0.7082\n",
      "-f1 Score: 0.7236\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4900\n",
      "-Precision: 0.4925\n",
      "-Recall: 0.4876\n",
      "-f1 Score: 0.4900\n",
      "===================================\n",
      "\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "Cross-validated Fq Score (Training): 0.5620\n",
      "K-Nearest Neighbors\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.6846\n",
      "-Precision: 0.6624\n",
      "-Recall: 0.7530\n",
      "-f1 Score: 0.7048\n",
      "-ROC AUC: 0.7539\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.5125\n",
      "-Precision: 0.5129\n",
      "-Recall: 0.5920\n",
      "-f1 Score: 0.5497\n",
      "-ROC AUC 0.5049\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Gradient Boosting Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5060\n",
      "Gradient Boosting Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.7639\n",
      "-Precision: 0.7788\n",
      "-Recall: 0.7373\n",
      "-f1 Score: 0.7575\n",
      "-ROC AUC: 0.8657\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4550\n",
      "-Precision: 0.4560\n",
      "-Recall: 0.4378\n",
      "-f1 Score: 0.4467\n",
      "-ROC AUC 0.4483\n",
      "===================================\n",
      "\n",
      "\n",
      "Training XGBoost...\n",
      "Cross-validated Fq Score (Training): 0.5082\n",
      "XGBoost\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.9207\n",
      "-Precision: 0.9212\n",
      "-Recall: 0.9201\n",
      "-f1 Score: 0.9207\n",
      "-ROC AUC: 0.9750\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4950\n",
      "-Precision: 0.4976\n",
      "-Recall: 0.5124\n",
      "-f1 Score: 0.5049\n",
      "-ROC AUC 0.4753\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Ada Boost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Fq Score (Training): 0.5317\n",
      "Ada Boost Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.6162\n",
      "-Precision: 0.6375\n",
      "-Recall: 0.5387\n",
      "-f1 Score: 0.5840\n",
      "-ROC AUC: 0.6756\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4700\n",
      "-Precision: 0.4654\n",
      "-Recall: 0.3682\n",
      "-f1 Score: 0.4111\n",
      "-ROC AUC 0.4665\n",
      "===================================\n",
      "\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 826, number of negative: 826\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 556\n",
      "[LightGBM] [Info] Number of data points in the train set: 1652, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 661, number of negative: 660\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 549\n",
      "[LightGBM] [Info] Number of data points in the train set: 1321, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500379 -> initscore=0.001514\n",
      "[LightGBM] [Info] Start training from score 0.001514\n",
      "[LightGBM] [Info] Number of positive: 660, number of negative: 661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 549\n",
      "[LightGBM] [Info] Number of data points in the train set: 1321, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499621 -> initscore=-0.001514\n",
      "[LightGBM] [Info] Start training from score -0.001514\n",
      "[LightGBM] [Info] Number of positive: 661, number of negative: 661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 549\n",
      "[LightGBM] [Info] Number of data points in the train set: 1322, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 661, number of negative: 661\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 549\n",
      "[LightGBM] [Info] Number of data points in the train set: 1322, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 661, number of negative: 661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 540\n",
      "[LightGBM] [Info] Number of data points in the train set: 1322, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Cross-validated Fq Score (Training): 0.5140\n",
      "LightGBM\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.8838\n",
      "-Precision: 0.8923\n",
      "-Recall: 0.8729\n",
      "-f1 Score: 0.8825\n",
      "-ROC AUC: 0.9528\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4800\n",
      "-Precision: 0.4824\n",
      "-Recall: 0.4776\n",
      "-f1 Score: 0.4800\n",
      "-ROC AUC 0.4987\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Naive bayes Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5719\n",
      "Naive bayes Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.6174\n",
      "-Precision: 0.5701\n",
      "-Recall: 0.9552\n",
      "-f1 Score: 0.7140\n",
      "-ROC AUC: 0.6346\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.5125\n",
      "-Precision: 0.5086\n",
      "-Recall: 0.8806\n",
      "-f1 Score: 0.6448\n",
      "-ROC AUC 0.4971\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Extra Tree Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5288\n",
      "Extra Tree Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 1.0000\n",
      "-Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "-f1 Score: 1.0000\n",
      "-ROC AUC: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4500\n",
      "-Precision: 0.4444\n",
      "-Recall: 0.3781\n",
      "-f1 Score: 0.4086\n",
      "-ROC AUC 0.4450\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Bagging Classifier...\n",
      "Cross-validated Fq Score (Training): 0.4825\n",
      "Bagging Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.9770\n",
      "-Precision: 0.9864\n",
      "-Recall: 0.9673\n",
      "-f1 Score: 0.9768\n",
      "-ROC AUC: 0.9977\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.5175\n",
      "-Precision: 0.5241\n",
      "-Recall: 0.4328\n",
      "-f1 Score: 0.4741\n",
      "-ROC AUC 0.4985\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Ridge Classifier...\n",
      "Cross-validated Fq Score (Training): 0.5401\n",
      "Ridge Classifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.6671\n",
      "-Precision: 0.6516\n",
      "-Recall: 0.7179\n",
      "-f1 Score: 0.6832\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4775\n",
      "-Precision: 0.4829\n",
      "-Recall: 0.5622\n",
      "-f1 Score: 0.5195\n",
      "===================================\n",
      "\n",
      "\n",
      "Training Neural Network MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Fq Score (Training): 0.5066\n",
      "Neural Network MLPClassifier\n",
      "Model performance for Training set\n",
      "-Accuracy: 0.9292\n",
      "-Precision: 0.9127\n",
      "-Recall: 0.9492\n",
      "-f1 Score: 0.9306\n",
      "-ROC AUC: 0.9839\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.4750\n",
      "-Precision: 0.4780\n",
      "-Recall: 0.4876\n",
      "-f1 Score: 0.4828\n",
      "-ROC AUC 0.4715\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUJAL GULIA\\anaconda3\\envs\\bail_model\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"Ada Boost Classifier\": AdaBoostClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"Naive bayes Classifier\": GaussianNB(),\n",
    "    \"Extra Tree Classifier\": ExtraTreesClassifier(),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "    \"Ridge Classifier\": RidgeClassifier(),\n",
    "    \"Neural Network MLPClassifier\": MLPClassifier()\n",
    "}\n",
    "model_list = []\n",
    "f1_list = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    if model_name in param_grids:\n",
    "        grid_search = GridSearchCV(model, param_grids[model_name], cv=3, scoring='f1', n_jobs=-1)\n",
    "        model = grid_search.fit(X_train, y_train).best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(f\"Cross-validated Fq Score (Training): {scores.mean():.4f}\")\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_train_proba = model.predict_proba(X_train)[:,1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_train_proba = None\n",
    "        y_test_proba = None\n",
    "\n",
    "    model_train_accuracy, model_train_precision, model_train_recall, model_train_f1, model_train_roc_auc = evaluate_model(y_train, y_train_pred, y_train_proba)\n",
    "    model_test_accuracy, model_test_precision, model_test_recall, model_test_f1, model_test_roc_auc = evaluate_model(y_test, y_test_pred,y_test_proba)\n",
    "    \n",
    "    print(model_name)\n",
    "    model_list.append(model_name)\n",
    "\n",
    "    print(\"Model performance for Training set\")\n",
    "    print(\"-Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "    print(\"-Precision: {:.4f}\".format(model_train_precision))\n",
    "    print(\"-Recall: {:.4f}\".format(model_train_recall))\n",
    "    print(\"-f1 Score: {:.4f}\".format(model_train_f1))\n",
    "    if model_train_roc_auc is not None:\n",
    "        print(\"-ROC AUC: {:.4f}\".format(model_train_roc_auc))\n",
    "    \n",
    "    print('----------------------------------')\n",
    "\n",
    "    print(\"Model performance for Test set\")\n",
    "    print(\"-Accuracy: {:.4f}\".format(model_test_accuracy))\n",
    "    print(\"-Precision: {:.4f}\".format(model_test_precision))\n",
    "    print(\"-Recall: {:.4f}\".format(model_test_recall))\n",
    "    print(\"-f1 Score: {:.4f}\".format(model_test_f1))\n",
    "    if model_test_roc_auc is not None:\n",
    "        print(\"-ROC AUC {:.4f}\".format(model_test_roc_auc))\n",
    "    f1_list.append(model_test_f1)\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bail_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
